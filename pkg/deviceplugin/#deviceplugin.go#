// TODO: remove orhpan interfaces in another thread
// TODO: use prestart container request, no need to wait
package deviceplugin

import (
	"context"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"net"
	"os"
	"os/exec"
	"time"

	dockertypes "github.com/docker/docker/api/types"
	dockercli "github.com/docker/docker/client"
	"github.com/golang/glog"
	"github.com/kubevirt/device-plugin-manager/pkg/dpm"
	"github.com/phoracek/kubetron/pkg/spec"
	"github.com/vishvananda/netlink"
	"k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	pluginapi "k8s.io/kubernetes/pkg/kubelet/apis/deviceplugin/v1beta1"
)

const (
	nicsPoolSize               = 100
	interfaceNamePrefix        = "nic_"
	letterBytes                = "abcdefghijklmnopqrstuvwxyz0123456789"
	fakeDeviceHostPath         = "/var/run/kubetron-fakedev"
	fakeDeviceGuestPath        = "/tmp/kubetron-fakedev"
	devicepluginCheckpointPath = "/var/lib/kubelet/device-plugins/kubelet_internal_checkpoint"
	networksSpecAnnotationName = "kubetron.network.kubevirt.io/networksSpec"
)

type Lister struct {
	ResourceName      string
	ResourceNamespace string
}

func (l Lister) GetResourceNamespace() string {
	glog.V(6).Infof("Getting namespace %s", l.ResourceNamespace)
	return l.ResourceNamespace
}

func (l Lister) Discover(pluginListCh chan dpm.PluginNameList) {
	glog.V(6).Infof("Discover called")
	pluginListCh <- dpm.PluginNameList{l.ResourceName}
	glog.V(6).Infof("Discover finished")
	// TODO: block?
}

func (l Lister) NewPlugin(bridge string) dpm.PluginInterface {
	glog.V(6).Infof("NewPlugin called")
	return DevicePlugin{}
}

type DevicePlugin struct {
	kubeclient   *kubernetes.Clientset
	dockerclient *dockercli.Client
}

func (dp DevicePlugin) GetDevicePluginOptions(ctx context.Context, in *pluginapi.Empty) (*pluginapi.DevicePluginOptions, error) {
	return &pluginapi.DevicePluginOptions{
		PreStartRequired: true,
	}, nil
}

func (dp *DevicePlugin) Start() error {
	glog.V(6).Infof("DP Start called")
	kubeClientConfig, err := rest.InClusterConfig()
	if err != nil {
		return fmt.Errorf("failed to obtain kubernetes client config: %v", err)
	}

	kubeclient, err := kubernetes.NewForConfig(kubeClientConfig)
	if err != nil {
		return fmt.Errorf("failed to intialize kubernetes client: %v", err)
	}
	dp.kubeclient = kubeclient
	// TODO: this fails, kubeclient is nil
	// TODO: maybe does not work since we dont get reference

	dockerclient, err := dockercli.NewEnvClient()
	if err != nil {
		return fmt.Errorf("failed to intialize docker client: %v", err)
	}
	dp.dockerclient = dockerclient

	err = createFakeDevice()

	glog.V(6).Infof("DP Start finished OK")
	return err
}

func (dp DevicePlugin) ListAndWatch(e *pluginapi.Empty, s pluginapi.DevicePlugin_ListAndWatchServer) error {
	glog.V(6).Infof("ListAndWatch called")
	for {
		var bridgeDevs []*pluginapi.Device
		for i := 0; i < nicsPoolSize; i++ {
			bridgeDevs = append(bridgeDevs, &pluginapi.Device{
				ID:     fmt.Sprintf("nic-%02d", i),
				Health: pluginapi.Healthy,
			})
		}
		s.Send(&pluginapi.ListAndWatchResponse{Devices: bridgeDevs})
		glog.V(6).Infof("ListAndWatch sent devices %s", bridgeDevs)
		time.Sleep(10 * time.Second)
	}
	return nil
}

func (dp DevicePlugin) Allocate(ctx context.Context, r *pluginapi.AllocateRequest) (*pluginapi.AllocateResponse, error) {
	glog.V(6).Infof("Allocate called")
	responses := pluginapi.AllocateResponse{}
	glog.V(6).Infof("1")

	// TODO: needed?
	for _, _ = range r.ContainerRequests {
		// TODO: MUST add device to reponse to trigger prestart, maybe?
		response := pluginapi.ContainerAllocateResponse{}
		responses.ContainerResponses = append(responses.ContainerResponses, &response)
	}

	if len(r.ContainerRequests) != 1 {
		return nil, fmt.Errorf("allocate request must contain exactly one container request")
	}
	glog.V(6).Infof("requests ok")

	if len(r.ContainerRequests[0].DevicesIDs) != 1 {
		return nil, fmt.Errorf("allocate request must contain exactly one device")
	}
	glog.V(6).Infof("devices ok")

	nic := r.ContainerRequests[0].DevicesIDs[0]

	// TODO: move this to pre start
	// TODO: why is this nil?????? temporary recreate client every time?
	go func() {

		glog.V(6).Infof("1")
		time.Sleep(10 * time.Second)

		checkpointRaw, err := ioutil.ReadFile(devicepluginCheckpointPath)
		if err != nil {
			panic(fmt.Errorf("failed to read device plugin checkpoint file: %v", err))
		}
		glog.V(6).Infof("2 raw: %s", checkpointRaw)

		var checkpoint map[string]interface{}
		err = json.Unmarshal(checkpointRaw, &checkpoint)
		if err != nil {
			panic(fmt.Errorf("failed to unmarshal device plugin checkpoint file: %v", err))
		}
		glog.V(6).Infof("3 cp: %s", checkpoint)

		podUID := ""
		glog.V(6).Infof("4")
	EntriesLoop:
		for _, entry := range checkpoint["PodDeviceEntries"].([]interface{}) {
			glog.V(6).Infof("5")
			for _, deviceID := range entry.(map[string]interface{})["DeviceIDs"].([]interface{}) {
				glog.V(6).Infof("6")
				if deviceID.(string) == nic {
					glog.V(6).Infof("7")
					podUID = entry.(map[string]interface{})["PodUID"].(string)
					glog.V(6).Infof("8")
					break EntriesLoop
				}
			}
		}
		if podUID == "" {
			panic(fmt.Errorf("failed to find PodUID"))
		}
		glog.V(6).Infof("9")

		var thePod v1.Pod
		podFound := false
		// TODO: looks like this fails, maybe kubeclient is not passed down?
		kubeClientConfig, err := rest.InClusterConfig()
		if err != nil {
			panic(fmt.Errorf("failed to obtain kubernetes client config: %v", err))
		}

		kubeclient, err := kubernetes.NewForConfig(kubeClientConfig)
		if err != nil {
			panic(fmt.Errorf("failed to intialize kubernetes client: %v", err))
		}
		glog.V(6).Infof("kubecli2 %s", kubeclient)
		pods, err := kubeclient.CoreV1().Pods("").List(metav1.ListOptions{})
		if err != nil {
			panic(fmt.Errorf("failed to list pods: %v", err))
		}
		glog.V(6).Infof("10")
		for _, pod := range pods.Items {
			glog.V(6).Infof("11")
			fmt.Println(pod.Name, pod.Status.PodIP)
			if string(pod.UID) == podUID {
				glog.V(6).Infof("12")
				thePod = pod
				podFound = true
				break
			}
		}
		glog.V(6).Infof("13")
		if !podFound {
			panic(fmt.Errorf("failed to find pod with given PodUID"))
		}

		glog.V(6).Infof("XXX the pod: %s", thePod)
		podName := thePod.Name
		podNamespace := thePod.Namespace
		var networksSpec spec.NetworksSpec
		annotations := thePod.ObjectMeta.GetAnnotations()
		networksSpecAnnotation, _ := annotations[networksSpecAnnotationName]

		// TODO: log labels, it is empty, huh
		err = json.Unmarshal([]byte(networksSpecAnnotation), &networksSpec)
		if err != nil {
			panic(fmt.Errorf("failed to read networks spec: %v", err))
		}
		glog.V(6).Infof("15")

		containerName := fmt.Sprintf("k8s_POD_%s_%s", podName, podNamespace)

		dockerclient, err := dockercli.NewEnvClient()
		if err != nil {
			panic(fmt.Errorf("failed to intialize docker client: %v", err))
		}

		containers, err := dockerclient.Container(context.Background(), dockertypes.ContainerListOptions{})
		if err != nil {
			panic(fmt.Errorf("failed to list docker containers: %v", err))
		}
		glog.V(6).Infof("16")

		containerPid := -1
		for i := 0; i <= 10; i++ {
			glog.V(6).Infof("17")
			for _, container := range containers {
				glog.V(6).Infof("18")
				config, err := dockerclient.ContainerInspect(context.Background(), container.ID)
				if err != nil {
					panic(fmt.Errorf("failed to inspect docker container: %v", err))
				}
				glog.V(6).Infof("19")

				if config.Name == containerName {
					containerPid = config.State.Pid
					glog.V(6).Infof("20")
					break
				}
				glog.V(6).Infof("21")
			}
			time.Sleep(10 * time.Second)
		}
		if containerPid == -1 {
			panic(fmt.Errorf("Failed to find container PID"))
		}
		glog.V(6).Infof("22")

		for _, spec := range networksSpec {
			glog.V(6).Infof("23")
			err = exec.Command(
				"ovs-vsctl", "--",
				"add-port", "br-int", spec.PortName, "--",
				"set", "Interface", spec.PortName, "type=internal",
			).Run()
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("24")

			port, err := netlink.LinkByName(spec.PortName)
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("25")

			err = netlink.LinkSetNsPid(port, containerPid)
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("26")

			hwaddr, err := net.ParseMAC(spec.MacAddress)
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("27")

			err = netlink.LinkSetHardwareAddr(port, hwaddr)
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("28")

			err = netlink.LinkSetUp(port)
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("29")

			err = exec.Command(
				"ovs-vsctl", "set", "Interface", spec.PortName, fmt.Sprintf("external_ids:iface-id=%s", spec.PortID),
			).Run()
			if err != nil {
				panic(err)
			}
			glog.V(6).Infof("30")
			// TODO: call dhclient ipam
		}

	}()

	glog.V(6).Infof("31")
	return &responses, nil
}

// TODO: did not get to here?, why, should be registered
func (dp DevicePlugin) PreStartContainer(ctx context.Context, r *pluginapi.PreStartContainerRequest) (*pluginapi.PreStartContainerResponse, error) {
	glog.V(6).Infof("PreStartContainer called")
	var response pluginapi.PreStartContainerResponse
	return &response, nil
}

func createFakeDevice() error {
	_, stat_err := os.Stat(fakeDeviceHostPath)
	if stat_err == nil {
		glog.V(3).Info("Fake block device already exists")
		return nil
	} else if os.IsNotExist(stat_err) {
		glog.V(3).Info("Creating fake block device")
		cmd := exec.Command("mknod", fakeDeviceHostPath, "b", "1", "1")
		err := cmd.Run()
		return err
	} else {
		panic(stat_err)
	}
}
